{
  "hash": "3d610d3bb7cfcec7ea38d7a9c1f0115e",
  "result": {
    "markdown": "---\ntitle: \"Project 2 Proposal: Clasifying generated data using Neural Networks in R\"\nauthor: \"Elliott Chang, Cameron Adams\"\nformat: html\neditor: visual\nexecute:\n  echo: false\n  warning: false\n  message: false\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(neuralnet)\nlibrary(shiny)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(cowplot)\nlibrary(knitr)\n```\n:::\n\n\n## Introduction\n\nMachine learning is fundamentally about exploiting patterns in data. Deep learning is a branch of machine learning which opts for huge expressive power, but loses almost all interpretability in the process. For this project we will be exploring *neural networks*, deep learning models which can (approximately) represent any function. Neural networks allow us to discover complex patterns in data that other models might not be able to predict.\n\nWe plan on illustrating the predictive power and flexibility of Neural Networks on data with complex relationships. We decided to focus on classification tasks, with applications in clustering and computer vision.\n\nResearch Question:\n\n-   How accurately can a simple neural network classify points with their correct clusters?\n\n-   What are the benefits of using a neural network over other algorithms?\n\n## What is a Neural Network?\n\nA neural network machine learning algorithm modeled on the human brain and nervous system (hence NEURAL network). Neural networks contain a lattice of nodes, organized into layers, each of which can be thought of as its own linear regression model. Analogously, the 'weights' associated to a node can be viewed as slope coefficients and 'biases' can be viewed as the intercept terms. These weights and biases are assigned randomly at first, then iteratively changed to reduce the training error. Each additional node allows for a different linear relationships and adding more 'layers' of nodes allows for more flexible, non-linear relationships. Similar to decision trees, one can think of neural networks as 'partitioning' the predictor space into regions of certain classes (in the context of classification).\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](data/neuralnetwork.png){fig-align='center' width=418}\n:::\n:::\n\n\n## Data Generation\n\nTo illustrate the power and flexibility of neural networks, we created multiple datasets with increasingly complex relationships.\n\nEach dataset contains two continuous predictor variables `x` and `y`, and one categorical response variable `label` with factors `a` and `b`.\n\nThe two continuous predictors allow us to visualize the relationship between these predictors easily, giving us an intuitive understand of what the underlying relationships might be. However, despite the intuitive nature of the relationships, more traditional models such as linear regression, logistic regression, and decision trees have trouble fitting to all of the data; even if one of these models can predict the relationship of a given dataset, their inflexibility prevents them from fitting well to all of the datasets.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nThis is where neural networks become extremely useful. Due to their previously mentioned flexibility, different neural networks with the exact same structure can be trained on vastly different datasets and still produce high predictive accuracy.\n\n\n::: {.cell}\n\n:::\n\n\nDisplayed below are some functions we developed for plotting the paritioning of the predictor space based on our model predictions and the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Code for plotting predictions\n\n# Function for creating a 200 by 200 grid of 'tiles'\ngenerate_grid <- function(data) {\n  x_range <- seq(min(data$x)-1, max(data$x)+1, length.out=200)\n  y_range <- seq(min(data$y)-1, max(data$y)+1, length.out=200)\n  grid <- expand.grid(x=x_range, y=y_range)\n  return(grid)\n}\n\n# Function for generating predictions for each 'tile'\npredict_grid <- function(model, grid) {\n  grid$pred <- predict(model, grid)\n  grid$pred_label <- ifelse(grid$pred[,1] > grid$pred[,2], 'a', 'b')\n  return(grid)\n}\n\n# Function for plotting the data as well as the predictions\nplot_prediction <- function(grid, data, title) {\n  ggplot() +\n    geom_tile(data=grid, aes(x=x, y=y, fill=pred_label), alpha=0.5) +\n    geom_point(data=data, aes(x=x, y=y, color=label), alpha=0.8) +\n    scale_fill_manual(values=c('a'='blue', 'b'='red')) +\n    scale_color_manual(values=c('a'='blue', 'b'='red')) +\n    labs(title=title, fill=\"Predicted Label\", color=\"Actual Label\") +\n    theme_minimal()\n}\n```\n:::\n\n\n## Model 1: Gaussian Distributed Data Model\n\nFor our first model, we wish to predict the classes based on our Gaussian distributed data. As a reminder, our data looks like:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nFor this, we will use a neural network with two hidden layers, each containing 5 nodes. The final model will consist of weights and biases for each node. The code for the model is displayed below, along with the architecture of the model, labeled with the weights and biases.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(932)\nmodel1 <- neuralnet(label~x+y, data=train1, hidden=c(5,5), linear.output=FALSE)\nd1 <- plot(model1, rep=\"best\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\nd1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNULL\n```\n:::\n:::\n\n\nNow, we can look at the confusion matrix to determine the overall accuracy of the model, as well as its sensitivity and specificity.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n   prediction_label\n      a   b\n  a 113   0\n  b   0  87\n```\n:::\n:::\n\n\nThis model produced a test accuracy of 100%! Display below, we have the predictor space with the plotted data, and the partitions created by the model to classify the points. \n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] 100\n```\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n## Model 2: Classes Split by Y-Axis\n\nFor our second model, we wish to predict the classes based on 'split' data. This data looks like:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\nAgain, we will use a neural network with two hidden layers, each containing 5 nodes. The code for the model is displayed below, along with the architecture of the model, labeled with the weights and biases. Notice that despite the architecture of the model being the same as the previous model, the associated weights and biases are different!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(932)\nmodel2 <- neuralnet(label~x+y, data=train2, hidden=c(5,5), linear.output=FALSE)\nplot(model2, rep=\"best\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nNow, we can look at the confusion matrix to determine the overall accuracy of the model, as well as its sensitivity and specificity.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n   prediction_label\n      a   b\n  a  99   0\n  b   0 101\n```\n:::\n:::\n\nThis model also produced a test accuracy of 100%! Display below, we have the predictor space with the plotted data, and the partitions created by the model to classify the points. \n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] 100\n```\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n## Model 3: Classes Split by Quadrants\n\nFor our third model, we wish to predict the classes based on data split into quadrants. This data looks like:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nFor the third model, we can also use a neural network with two hidden layers, each containing 5 nodes (remember, flexibility)! The code for the model is displayed below, along with the architecture of the model, labeled with the weights and biases. Again, despite the architecture of the model being the same as the previous two models, the associated weights and biases are different!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(932)\nmodel3 <- neuralnet(label~x+y, data=train3, hidden=c(5,5), linear.output=FALSE)\nplot(model3, rep=\"best\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nNow, we can look at the confusion matrix to determine the overall accuracy of the model, as well as its sensitivity and specificity.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n   prediction_label\n      a   b\n  a 105   0\n  b   0  95\n```\n:::\n:::\n\n\nThis model also produced a test accuracy of 100%! Display below, we have the predictor space with the plotted data, and the partitions created by the model to classify the points. \n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] 100\n```\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n## Model 4: Spiral Data\n\nFinally, for our fourth model, we wish to predict the classes based on spiral, by far the most complex relationship of the bunch. This data looks like:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\nHere, to illustrate how imperative the architecture of the model is to its accuracy, we will fit three different models. The first model is a simple neural network with no hidden layers. This is esentially equivalent to running a linear regression model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(932)\nmodel4_no_layers <- neuralnet(\n    label~x + y,\n    data=train4,\n    linear.output=FALSE,\n    learningrate=0.001,\n    stepmax=1e+06\n)\n```\n:::\n\n\nUnsurprisingly, after testing our model on the testing data, we can see that the model only produced a 58% test accuracy, only slightly more accurate than randomly guessing the classes of the points.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n   prediction_label\n     a  b\n  a 56 41\n  b 43 60\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 58\n```\n:::\n:::\n\nDisplayed below is a visualization of the predictions our model is making:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n\nThe second model has only one hidden layer with 5 nodes, a slightly more complex model than the previous one.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(932)\nmodel4_5node_layer <- neuralnet(\n    label~x + y,\n    data=train4,\n    hidden=c(5),\n    linear.output=FALSE,\n    learningrate=0.001,\n    stepmax=1e+06\n)\n```\n:::\n\n\nAfter testing our model on the testing data, we can see that the model produced a 73% test accuracy, a large improvement from our previous model\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n   prediction_label\n     a  b\n  a 65 32\n  b 22 81\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 73\n```\n:::\n:::\n\n\nWe can also see that the partitions of the predictor space are slightly more complex.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\nFinally, our third model is the most complex with two hidden layers each containing 8 nodes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(932)\nmodel4 <- neuralnet(\n    label~x + y,\n    data=train4,\n    hidden=c(8,8),\n    linear.output=FALSE,\n    learningrate=0.001,\n    stepmax=1e+06\n)\n```\n:::\n\n\nAfter testing this model on the testing data, we can see that the model produced a 98% test accuracy, significantly better than either of our previous models!\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n   prediction_label\n      a   b\n  a  96   1\n  b   3 100\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 98\n```\n:::\n:::\n\nThe complexity of our model as well as the high predictive accuracy are reflected in the partitions of the predictor space.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\n## Discussion and Conclusion\n\nAs we showed, our neural networks were able to find the patterns in our data set relatively easily. The first three (Gauss, X, XY) data sets use pretty simple neural networks that didn't take too long to train and were extremely accurate, getting accuracy all greater than 99%. The Spiral data set was much more complex, and needed a more complex neural network which required more time, but it was able to accurately (98%, with it actually being close to impossible to get 100% as some data points with different labels overlapped) label the data. We were able to show case these with our default values in our presentation and shiny app, with users able to use the shinny app to explore their own neural network architectures in order to see the impact on each data set. The caveat is that the spiral data set would often crash R if messed around with too much but the shinny app worked well with the other data sets. In conclusion we are very happy with our project and believe we adiquetly illustrated the power of neural networks\n\nThis was a pretty basic showcase of the power of Neural networks, but there's so much that could be built off of what we've done. While working on this we discussed that what we were doing was not too far off of banknote security. As an extension, one could take a fraudulent bank note data set and see how well different network architectures would do on a bank note data set, or even more complex cyber security problems.\n\nFinally, displayed below is the code for a Shiny App that allows users to train their own neural networks on the four datasets we created.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nui <- fluidPage(\n  titlePanel(\"Neural Networks Visualization\"),\n  sidebarLayout(\n    sidebarPanel(\n      selectInput(\"dataset\", \"Choose a dataset:\", choices = c(\"Gaussian distribution\" = \"data_two\",\n                                                             \"Horizontal split\" = \"data_by_x\", \n                                                             \"Quadrants\" = \"data_by_xy\", \n                                                             \"Spiral data\" = \"spiral_data\")),\n      selectInput(\"learningRate\", \"Choose Learning rate\", choices = c(\"default\",\n                                                                      \"0.3\", \n                                                                      \"0.01\", \n                                                                      \"0.003\", \n                                                                      \"0.001\", \n                                                                      \"0.0003\",\n                                                                      \"0.0001\")),\n      selectInput(\"HiddenLayers\", \"Choose Number of nodes in 2 layers:\", choices = c(\"default\",\n                                                                                 \"3\", \n                                                                                 \"4\", \n                                                                                 \"5\",\n                                                                                 \"6\",\n                                                                                 \"7\",\n                                                                                 \"8\",\n                                                                                 \"9\")),\n      actionButton(\"runModel\", \"Run Model\")\n    ),\n    mainPanel(\n      plotOutput(\"scatterPlot\")\n    )\n  )\n)\n\nserver <- function(input, output) {\n  plotData <- reactive({\n    \n    #basic pulls with default from above\n    if (input$HiddenLayers == \"default\" && input$learningRate == \"default\") {\n      # Choose which pre-generated plot to display based on the dataset\n      if (input$dataset == \"data_two\") {\n        p1\n      } else if (input$dataset == \"data_by_x\") {\n        p2\n      } else if (input$dataset == \"data_by_xy\") {\n        p3\n      } else {  # \"spiral_data\"\n        p4\n      }\n    } else {\n      \n      # Convert numeric if not 'default'\n      hidden_layers <- ifelse(input$HiddenLayers != \"default\", rep(as.numeric(input$HiddenLayers), as.numeric(input$HiddenLayers)), c(5,5))\n      learning_rate <- ifelse(input$learningRate != \"default\", as.numeric(input$learningRate), 0.01)\n\n      \n      # Dynamic model function\n      run_model <- function(data, \n                            hidden=hidden_layers,\n                            rate=learning_rate) {\n                                                 neuralnet(label~x+y, \n                                                 data=data, \n                                                 hidden=hidden,\n                                                 learningrate=rate,\n                                                 linear.output=FALSE, \n                                                 stepmax=1e+06)\n      }\n\n      data_list <- list(data_two = train1, data_by_x = train2, data_by_xy = train3, spiral_data = train4)\n\n      model <- run_model(data_list[[input$dataset]])\n\n      \n      grid <- generate_grid(data_list[[input$dataset]])\n      grid$pred_label <- predict_grid(model, grid)$pred_label\n      plot_prediction(grid, data_list[[input$dataset]], paste(\"Model Predictions with LR =\", learning_rate, \", Hidden Layers =\", toString(hidden_layers)))\n    }\n  })\n\n  # Only update the output plot when the button is clicked, doesnt really work\n  observeEvent(input$runModel, {\n    output$scatterPlot <- renderPlot({\n      plotData()\n    })\n  }, ignoreInit = TRUE)\n}\n\nshinyApp(ui = ui, server = server)\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}