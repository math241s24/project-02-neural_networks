{
  "hash": "b1c35b9c06de1936cffb84ba23fb3480",
  "result": {
    "markdown": "---\ntitle: \"Project 2 Proposal: Cartoon Character Classification using Neural Networks\"\nsubtitle: \"Proposal\"\nauthors: \"\"\nformat: html\neditor: visual\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(neuralnet)\nlibrary(ggplot2)\nlibrary(dplyr)\n```\n:::\n\n\n## Goal\n\nOur project aims to develop a neural network model capable of predicting and classifying images based the brightness of individual pixels, utilizing the `neuralnet` and `keras` packages in R, in service of introducing the concept of neural networks to the class and exploring how neural networks can be trained in R, specifically in the context of computer vision and image classification.\n\n## Dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngenGauss <- function(cx, cy, num_samples, variance, label) {\n  x <- rnorm(num_samples, mean = cx, sd = sqrt(variance))\n  y <- rnorm(num_samples, mean = cy, sd = sqrt(variance))\n  data.frame(x = x, y = y, label = label)\n}\n\n#generates two clusters of data points\nclassifyTwoGaussData <- function(num_samples, noise) {\n  variance_scale <- function(noise) {\n    (1 - noise) * 0.5 + noise * 4\n  }\n  variance <- variance_scale(noise)\n  \n  points1 <- genGauss(2, 2, num_samples / 2, variance, 1)\n  points2 <- genGauss(-2, -2, num_samples / 2, variance, -1)\n  \n  # Combine  datasets\n  points <- rbind(points1, points2)\n  return(points)\n}\n\n\nset.seed(123) \ndata_two <- classifyTwoGaussData(1000, 0.1)\n\n# show data\nggplot(data_two, aes(x = x, y = y, color = factor(label))) +\n  geom_point(alpha = 0.6) +\n  labs(title = \"Classify Two Gauss Data\", color = \"Label\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](proposal_files/figure-html/load-data-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngenerateDataByX <- function(num_samples) {\n  x <- runif(num_samples, min = -5, max = 5)\n  y <- runif(num_samples, min = -5, max = 5) \n  label <- ifelse(x >= 0, 1, -1)              \n  \n  data <- data.frame(x = x, y = y, label = label)\n  return(data)\n}\n\nset.seed(123) \ndata_by_x <- generateDataByX(1000)\n\n#plot\nggplot(data_by_x, aes(x = x, y = y, color = factor(label))) +\n  geom_point(alpha = 0.6) +\n  labs(title = \"Data Classified by X Value\", color = \"Label\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](proposal_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngenerateDataByXYProduct <- function(num_samples) {\n  x <- runif(num_samples, min = -5, max = 5) \n  y <- runif(num_samples, min = -5, max = 5)\n  label <- ifelse(x * y >= 0, 1, -1)         \n  \n  data <- data.frame(x = x, y = y, label = label)\n  return(data)\n}\n\nset.seed(123) \ndata_by_xy <- generateDataByXYProduct(1000)\n\nggplot(data_by_xy, aes(x = x, y = y, color = factor(label))) +\n  geom_point(alpha = 0.6) +\n  labs(title = \"Data Classified by XY Product\", color = \"Label\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](proposal_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nThe dataset consists of pixel brightness for images of clothing of various types. Each observation represents an individual $28 \\times 28$ grayscale image of an item of clothing, with a variable `label` indicating the type of clothing (0 - T-shirt/top; 1 - Trouser; 2 - Pullover; 3 - Dress, 4 - Coat; 5 - Sandal; 6 - Shirt; 7 - Sneaker; 8 - Bag; 9 - Ankle boot) and 784 other variables, each representing the brightness of a unique pixel in the image (ordered sequentially from left to right, top to bottom). The training dataset `fashion_train` contains 60,000 observations and the testing dataset contains 10,000 observations. We chose this data because it is easy to work with and ideal when learning about how neural networks are trained.\n\n## Motivation\n\nNeural networks represent a cornerstone of modern machine learning, offering significant power in pattern recognition, classification, and prediction tasks. Despite their widespread application across various domains, their implementation and functionality remain a mystery to many. Even to our group, of which both of us have *some* experience in neural networks, the underlying machinery is fairly opaque. We aim to demystify neural networks, showcasing their capabilities and how they can be implemented using the `neuralnet` package in R. This project not only serves an educational purpose but also demonstrates practical application in image classification, a prevalent task in AI. The goal will be to make a website and blog post, with the website hopefully being interactive so that people can get a more intuitive understanding of how neural networks work..\n\n## Research Question\n\nOur research question is twofold: how accurately can a simple neural network classify images of clothing into their correct categories, based on the brightness of the pixels? and what is the underlying process that allows neural networks to be trained.\n\n## Plan of Attack\n\nAfter this week we have 3 weeks to complete our project and present it: so here are our goal outlines\n\n-   Week 11: train our neural networks, attempting to tune the architecture of our model such that it is simple but produces high predictive test accuracy.\n\n-   Week 12: write code for our website and link our code into the shiny app before peer reviewÂ \n\n-   Week 13: work with peer review to clean up our code for our presentation\n\n-   Week 14/15: write up with blog post\n\n## Project Repository Organization\n\nThe project repository is organized as follows:\n\n-   `/_freeze` - Contains files relating to the website.\n-   `/_site` - Contains files relating to the website.\n-   `/data` - Contains the dataset of cartoon character images.\n-   `/models` - Stores the trained neural network models.\n-   `about.qmd` - Project description to appear on website\n-   `proposal.qmd` - Project proposal\n-   `index.qmd` - Project write-up\n-   `presentation.qmd` - Project presentation\n\nEach folder includes a README.md explaining the contents and structure.\n",
    "supporting": [
      "proposal_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}