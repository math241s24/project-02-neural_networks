{
  "hash": "6e1c5d324d09d115875b18448eee43d2",
  "result": {
    "markdown": "---\ntitle: \"Project 2 Proposal: Clasifying generated data using Neural Networks in R\"\nsubtitle: \"Proposal\"\nauthors: \"\"\nformat: html\neditor: visual\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(neuralnet)\nlibrary(ggplot2)\nlibrary(dplyr)\n```\n:::\n\n\n## Goal\n\nOur project aims to develop a neural network model capable of predicting and classifying our own generated data sets, utilizing the `neuralnet` and `keras` packages in R, in service of introducing the concept of neural networks to the class and exploring how neural networks can be trained in R, specifically in the context of computer vision and data set classification.\n\n## Dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngenGauss <- function(cx, cy, num_samples, variance, label) {\n  x <- rnorm(num_samples, mean = cx, sd = sqrt(variance))\n  y <- rnorm(num_samples, mean = cy, sd = sqrt(variance))\n  data.frame(x = x, y = y, label = label)\n}\n\n#generates two clusters of data points\nclassifyTwoGaussData <- function(num_samples, noise) {\n  variance_scale <- function(noise) {\n    (1 - noise) * 0.5 + noise * 4\n  }\n  variance <- variance_scale(noise)\n  \n  points1 <- genGauss(2, 2, num_samples / 2, variance, 1)\n  points2 <- genGauss(-2, -2, num_samples / 2, variance, -1)\n  \n  # Combine  datasets\n  points <- rbind(points1, points2)\n  return(points)\n}\n\n\nset.seed(123) \ndata_two <- classifyTwoGaussData(1000, 0.1)\n\n# show data\nggplot(data_two, aes(x = x, y = y, color = factor(label))) +\n  geom_point(alpha = 0.6) +\n  labs(title = \"Classify Two Gauss Data\", color = \"Label\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](proposal_files/figure-html/load-data-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngenerateDataByX <- function(num_samples) {\n  x <- runif(num_samples, min = -5, max = 5)\n  y <- runif(num_samples, min = -5, max = 5) \n  label <- ifelse(x >= 0, 1, -1)              \n  \n  data <- data.frame(x = x, y = y, label = label)\n  return(data)\n}\n\nset.seed(123) \ndata_by_x <- generateDataByX(1000)\n\n#plot\nggplot(data_by_x, aes(x = x, y = y, color = factor(label))) +\n  geom_point(alpha = 0.6) +\n  labs(title = \"Data Classified by X Value\", color = \"Label\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](proposal_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nTo illustrate the power and flexibility of neural networks, we created multiple datasets with increasingly complex relationships, one that Each dataset contains two continuous predictor variables `x` and `y`, and one categorical response variable `label` with factors a and b.Two continuous predictors allow us to visualize the relationships between these predictors easily, giving us an intuitive understand of what the underlying relationships might be. However, despite the intuitive nature of the relationships, more traditional models such as linear regression, logistic regression, and decision trees have trouble fitting to all of the data; even if one of these models can predict the relationship of a given dataset, their inflexibility prevents them from fitting well to all of the datasets.\n\n## Motivation\n\nNeural networks represent a cornerstone of modern machine learning, offering significant power in pattern recognition, classification, and prediction tasks. Despite their widespread application across various domains, their implementation and functionality remain a mystery to many. Even to our group, of which both of us have *some* experience in neural networks, the underlying machinery is fairly opaque. We aim to demystify neural networks, showcasing their capabilities and how they can be implemented using the `neuralnet` package in R. This project not only serves an educational purpose but also demonstrates practical application in image classification, a prevalent task in AI. The goal will be to make a website and blog post, with the website hopefully being interactive so that people can get a more intuitive understanding of how neural networks work..\n\n## Research Question\n\nOur research question is twofold: how accurately can different neural networks classify different simple to slightly complex generated datasets and what is the underlying process that allows neural networks to be trained.\n\n## Plan of Attack\n\nAfter this week we have 3 weeks to complete our project and present it: so here are our goal outlines\n\n-   Week 11: train our neural networks, attempting to tune the architecture of our model such that it is simple but produces high predictive test accuracy.\n\n-   Week 12: write code for our website and link our code into the shiny app before peer reviewÂ \n\n-   Week 13: work with peer review to clean up our code for our presentation\n\n-   Week 14/15: write up with blog post\n\n## Project Repository Organization\n\nThe project repository is organized as follows:\n\n-   `/_freeze` - Contains files relating to the website.\n-   `/_site` - Contains files relating to the website.\n-   `/data` - Contains the dataset of cartoon character images.\n-   `/models` - Stores the trained neural network models.\n-   `about.qmd` - Project description to appear on website\n-   `proposal.qmd` - Project proposal\n-   `index.qmd` - Project write-up\n-   `presentation.qmd` - Project presentation\n\nEach folder includes a README.md explaining the contents and structure.\n",
    "supporting": [
      "proposal_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}