---
title: "Project 2 Proposal: Cartoon Character Classification using Neural Networks"
subtitle: "Proposal"
authors: ""
format: html
editor: visual
---

```{r load-packages}
#| label: load-pkgs
#| message: false
#| warning: false

library(tidyverse)
library(neuralnet)
library(keras)
library(tensorflow)
```

## Goal

Our project aims to develop a neural network model capable of predicting and classifying images based the brightness of individual pixels, utilizing the `neuralnet` and `keras` packages in R, in service of introducing the concept of neural networks to the class and exploring how neural networks can be trained in R, specifically in the context of computer vision and image classification.

## Dataset

```{r load-packages}
#| label: load-pkgs
#| message: false
#| warning: false

library(tidyverse)
library(neuralnet)
library(keras)
library(tensorflow)
library(keras)
library(ggplot2)
library(reshape2)
library(dplyr)

```

```{r load-data}
#| label: load-data
#| message: false


genGauss <- function(cx, cy, num_samples, variance, label) {
  x <- rnorm(num_samples, mean = cx, sd = sqrt(variance))
  y <- rnorm(num_samples, mean = cy, sd = sqrt(variance))
  data.frame(x = x, y = y, label = label)
}

#generates two clusters of data points
classifyTwoGaussData <- function(num_samples, noise) {
  variance_scale <- function(noise) {
    (1 - noise) * 0.5 + noise * 4
  }
  variance <- variance_scale(noise)
  
  points1 <- genGauss(2, 2, num_samples / 2, variance, 1)
  points2 <- genGauss(-2, -2, num_samples / 2, variance, -1)
  
  # Combine  datasets
  points <- rbind(points1, points2)
  return(points)
}


set.seed(123) 
data_two <- classifyTwoGaussData(1000, 0.1)

# show data
ggplot(data_two, aes(x = x, y = y, color = factor(label))) +
  geom_point(alpha = 0.6) +
  labs(title = "Classify Two Gauss Data", color = "Label") +
  theme_minimal()

```

```{r}

generateDataByX <- function(num_samples) {
  x <- runif(num_samples, min = -5, max = 5)
  y <- runif(num_samples, min = -5, max = 5) 
  label <- ifelse(x >= 0, 1, -1)              
  
  data <- data.frame(x = x, y = y, label = label)
  return(data)
}

set.seed(123) 
data_by_x <- generateDataByX(1000)

#plot
ggplot(data_by_x, aes(x = x, y = y, color = factor(label))) +
  geom_point(alpha = 0.6) +
  labs(title = "Data Classified by X Value", color = "Label") +
  theme_minimal()
```

```{r}
generateDataByXYProduct <- function(num_samples) {
  x <- runif(num_samples, min = -5, max = 5) 
  y <- runif(num_samples, min = -5, max = 5)
  label <- ifelse(x * y >= 0, 1, -1)         
  
  data <- data.frame(x = x, y = y, label = label)
  return(data)
}

set.seed(123) 
data_by_xy <- generateDataByXYProduct(1000)

ggplot(data_by_xy, aes(x = x, y = y, color = factor(label))) +
  geom_point(alpha = 0.6) +
  labs(title = "Data Classified by XY Product", color = "Label") +
  theme_minimal()


```

```{r}


# the three data sets we have

#data_two
#data_by_x 
#data_by_xy 


create_model <- function() {
  model <- keras_model_sequential()
  model %>%
    layer_dense(units = 8, activation = 'relu', input_shape = c(2)) %>%
    layer_dense(units = 4, activation = 'relu') %>%
    layer_dense(units = 1, activation = 'sigmoid')
  
  model %>% compile(
    loss = 'binary_crossentropy',
    optimizer = optimizer_rmsprop(),
    metrics = c('accuracy')
  )
  return(model)
}


# Train model for the first dataset
model1 <- create_model()
history1 <- model1 %>% fit(
  as.matrix(data_two[, 1:2]),
  as.matrix(data_two[, 3]),
  epochs = 100,
  batch_size = 10,
  validation_split = 0.2
)

# Train model for the first dataset
model2 <- create_model()
history1 <- model1 %>% fit(
  as.matrix(data_by_x[, 1:2]),
  as.matrix(data_by_x[, 3]),
  epochs = 100,
  batch_size = 10,
  validation_split = 0.2
)

# Train model for the second dataset
model3 <- create_model()
history2 <- model2 %>% fit(
  as.matrix(data_by_xy[, 1:2]),
  as.matrix(data_by_xy[, 3]),
  epochs = 100,
  batch_size = 10,
  validation_split = 0.2
)

```

```{r}

# read in data
fashion_train1 <- read_csv(file = "data/fashion_train1.csv")
fashion_train2 <- read_csv(file = "data/fashion_train2.csv")
fashion_test <- read_csv(file = "data/fashion-mnist_test.csv")

#combine training datasets
fashion_train<- rbind(fashion_train1, fashion_train2)

# normalize pixel values to [0,1]
fashion_train[-1] <- fashion_train[-1] / 255
fashion_test[-1] <- fashion_test[-1] / 255

#dimensions of datasets
dim(fashion_test)
dim(fashion_train)
```

The dataset consists of pixel brightness for images of clothing of various types. Each observation represents an individual $28 \times 28$ grayscale image of an item of clothing, with a variable `label` indicating the type of clothing (0 - T-shirt/top; 1 - Trouser; 2 - Pullover; 3 - Dress, 4 - Coat; 5 - Sandal; 6 - Shirt; 7 - Sneaker; 8 - Bag; 9 - Ankle boot) and 784 other variables, each representing the brightness of a unique pixel in the image (ordered sequentially from left to right, top to bottom). The training dataset `fashion_train` contains 60,000 observations and the testing dataset contains 10,000 observations. We chose this data because it is easy to work with and ideal when learning about how neural networks are trained.

## Motivation

Neural networks represent a cornerstone of modern machine learning, offering significant power in pattern recognition, classification, and prediction tasks. Despite their widespread application across various domains, their implementation and functionality remain a mystery to many. Even to our group, of which both of us have *some* experience in neural networks, the underlying machinery is fairly opaque. We aim to demystify neural networks, showcasing their capabilities and how they can be implemented using the `neuralnet` package in R. This project not only serves an educational purpose but also demonstrates practical application in image classification, a prevalent task in AI. The goal will be to make a website and blog post, with the website hopefully being interactive so that people can get a more intuitive understanding of how neural networks work..

## Research Question

Our research question is twofold: how accurately can a simple neural network classify images of clothing into their correct categories, based on the brightness of the pixels? and what is the underlying process that allows neural networks to be trained.

## Plan of Attack

After this week we have 3 weeks to complete our project and present it: so here are our goal outlines

-   Week 11: train our neural networks, attempting to tune the architecture of our model such that it is simple but produces high predictive test accuracy.

-   Week 12: write code for our website and link our code into the shiny app before peer reviewÂ 

-   Week 13: work with peer review to clean up our code for our presentation

-   Week 14/15: write up with blog post

## Project Repository Organization

The project repository is organized as follows:

-   `/_freeze` - Contains files relating to the website.
-   `/_site` - Contains files relating to the website.
-   `/data` - Contains the dataset of cartoon character images.
-   `/models` - Stores the trained neural network models.
-   `about.qmd` - Project description to appear on website
-   `proposal.qmd` - Project proposal
-   `index.qmd` - Project write-up
-   `presentation.qmd` - Project presentation

Each folder includes a README.md explaining the contents and structure.
